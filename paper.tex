\documentclass[11pt]{article}
\usepackage{acl2016}
\usepackage{times}

\usepackage{url}
\usepackage{latexsym}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{graphicx}
\usepackage{paralist}
\usepackage{mathtools}
\usepackage{dingbat}
\usepackage{subcaption}
\usepackage{balance}
\usepackage{gensymb}
\usepackage{marginnote}
\usepackage{adjustbox}

\sloppy

% \aclfinalcopy % Uncomment this line for the final submission
% \def\aclpaperid{34} %  Enter the acl Paper ID here


\usepackage{color}
\newcommand{\todo}[1]{}
\renewcommand{\todo}[1]{{\color{red} TODO: {#1}}}

% \renewcommand{\baselinestretch}{0.95}

%\setlength\titlebox{5cm}

% You can expand the titlebox if you need extra space
% to show all the authors. Please do not make the titlebox
% smaller than 5cm (the original size); we will check this
% in the camera-ready version and ask you to change it back.

\title{On Similarity}

% \author{First Author \\
%   Affiliation / Address line 1 \\
%   Affiliation / Address line 2 \\
%   Affiliation / Address line 3 \\
%   {\tt email@domain} \\\And
%   Second Author \\
%   Affiliation / Address line 1 \\
%   Affiliation / Address line 2 \\
%   Affiliation / Address line 3 \\
%   {\tt email@domain} \\}

\date{}

\begin{document}

\maketitle

\begin{abstract}

\end{abstract}

\section{Introduction}
\label{sec:introduction}

Similarity plays a crucial role in psychological theories of knowledge and behaviour. For example, it is used for classification and conceptualisation \cite{Tversky1977}. \textit{Fruit} is a \emph{category} because it is a practical generalisation: Fruits are sweet and constitute deserts, so when one is presented with an unseen fruit, one can hypothesise that it is served towards the end of a dinner.

Generalisations are extremely powerful in describing a language as well. The verb \textit{runs} requires its subject to be singular. \textit{Verb}, \textit{subject} and \textit{singular} are categories that are used to describe English grammar. When one encounters an unknown word and is told that it is a verb, one will immediately have an idea how to use it assuming that it is used similarly to other English verbs.

Semantic formalisation of similarity bases on two ideas. Word occurrence patterns \emph{define} its meaning \cite{firth1957lingtheory}, while the difference in occurrence \textup{quantifies} the difference in meaning \cite{harris1954distributional}. From computational perspective, this motivates and guides development of similarity components that are embedded into natural language processing systems that deal with tasks such as word sense disambiguation \cite{Schutze:1998:AWS:972719.972724}, information retrieval \cite{Salton:1975:VSM:361219.361220} and machine translation \cite{Dagan:1993:CWS:981574.981596}.

Because it is difficult to measure performance of a single (similarity) component in a pipeline, datasets that focus on similarity are popular among computational linguists. Apart from a pragmatic attempt to alleviate the evaluation of similarity components, these datasets serve as an empirical test of the hypotheses of Firth and Harris, merging together our understanding of human mind, language and technology.

Two datasets, namely MEN \cite{Bruni:2012:DST:2390524.2390544} and SimLex-999 \cite{hill2014simlex}, are currently widely used. They are designed especially for meaning representation evaluation and surpass datasets stemming from psychology \cite{1986-13502-00119860101} and information retrieval \cite{2002:PSC:503104.503110} in quantity by having more entries and, in case of SimLex-999, attention to the evaluated relation by distinguishing similarity from relatedness.

Similarity is the degree of resemblance between two objects or events \cite{WCS:WCS1282}. It can be implemented as a Contrast Model where the similarity between objects is expressed as a function of their common and distinctive features \cite{Tversky1977}. The datasets provide \emph{global} similarity (relatedness) scores between word pairs. Global similarity refers to an overall comparison \cite{hahn1997concepts} and is restricted with regard to the following observations:
\begin{compactitem}
    % \item Similarity scores group words to categories that are formed around \emph{focal points}, the terms that represent clusters.
    % To detect a focal point, one needs similarities between all words, or pairings between the focal point and the words of a category for each category.
    \item Similarity is measured with respect to something: \textit{apple} is similar to \textit{orange} because both are companies or kinds of fruits, but dissimilar because apples grow where oranges do not \cite{hahn1997concepts}.
    \item Similarity scores presented by the datasets are ambiguous as it is not really clear what low similarity values mean: incompatible notions (\textit{trick} and \textit{size}) or contrast in meaning (\textit{smart} and \textit{dumb}). For example, SimLex-999 assigns low similarity scores to the pairs, 0.48 and 0.55 out of 10 respectively, but \textit{smart} and \textit{dumb} have relatively much more in common than \textit{trick} and \textit{size}!

    % TODO: \cite{Roth1983346}
    % TODO: this also leads to the extension of the similarity task: items are similar *because* of certain respect. Relevant respects have to be identified.
\end{compactitem}
%
Consequently, we argue that a similarity task should be altered, so that a similarity model, instead of estimation of global similarity, provides similarity score together with a \emph{respect} the items are similar to \cite{hahn1997concepts}.

% TODO: wrap up the introduction and make a transition to the next sections.

\section{Treating similarity with respect}

% TODO: think of "respects". Goodman, Goldstone. Refer to Koen Lamberts & David Shanks "Knowledge, Concepts and Categories" page 51.
% TODO: "Another possibility is that similarity and concepts are mutually constraining, and that neither presupposes the other." Lamberts&Shanks p. 66.

Similarity is measured with respect to something \cite{Roth1983346,Sadler1993}. It is very inaccurate (and probably impossible) to estimate the global similarity of ambiguous terms such as \textit{apple} and \textit{orange}. The two fruits are almost identical with respect to the shape, but have different taste. Both of them are used for juice production, thus have similar agricultural use. On the other hand, both of them are multinational companies, but they operate in different industries: technology and telecommunications. One could say that ``\textit{apple}'s similarity to \textit{orange} is 8 out of 10 because they are both \textit{fruits}'' and ``as a company, \textit{apple}'s similarity to \textit{orange} is 6 out of 10.'' The context similarity is measured in is called \emph{respect} \cite{hahn1997concepts}.

Once a representative number of similarity judgements is collected, a global similarity can be estimated by simply ignoring the respects. However, the respects themselves convey an important information. Hypothetically, a dominant respect between fruits is \textit{fruit}, cars is \textit{car} and so on. Thus, respects can be seen as clusters, which similarity models need to identify. This solves the problem of ambiguity of low similarity scores, since there is no need to compare incompatible pairs. If there is no respect that ``connects'' two notions, this means that there is no similarity relation between them.
% TODO: is it clear enough?

Clustering is appealing because of another factor. If a category has a superordinate, similarity judgements arrange objects around it \cite{1986-13502-00119860101}. For example, similarity judgements given by humans arrange fruit names around the word \textit{fruit} in such a way that it is their nearest neighbour, making \textit{fruit} the \emph{focal point} of the category of \textit{fruits}. As an additional evaluation method, the model should be able to retrieve focal points. Note, however, that existing lexical databases such as WordNet \cite{Miller:1995:WLD:219717.219748} cannot be used to recognise focal points. As \newcite{turney2012domain} points out, categories that emerge from similarity judgements are different from taxonomies. For example, \textit{traffic} and \textit{water} might be considered to be similar because of a functional similarity exploited in hydrodynamic models of traffic, but their lowest common ancestor in WordNet is \textit{entity}.

We propose to extend the similarity model evaluation to include classification, to overcome difficulties of uncontextualised similarity scores which might be due to the fact the similarity and concepts are computed simultaneously by humans \cite{hahn1997concepts}.

\section{Phrase and sentence similarity}

In the previous section we focused on the properties of similarity, illustrating it with word-word examples. This section is dedicated to the nuances of similarity measurement between words, phrases and sentences. We assume that similarity requires the agreement of the grammatical roles of the words or phrases.

A noun phrase can be similar to a noun, as in \textit{female lion} and \textit{lioness}, as between noun phrases with modifiers (\textit{yellow car} and \textit{taxi}), so the same similarity principles can be applied to phrases as to words. In this case, similarity is measured in \emph{context}. It is still comparison of heads which meaning is modified by arguments they appear with \cite{Dinu:2010:MDS:1870658.1870771,mitchell2010composition}. With verbs this idea can be applied to compare transitive verbs with intransitive. For example, \textit{to cycle} is similar to \textit{ride a bicycle}.

Sentential similarity can be explained in several ways. First of all, it might be seen as the similarity of the heads in the contexts. That is, the similarity between \textit{sees} and \textit{notices} in \textit{John \textbf{sees} Mary} and \textit{John \textbf{notices} a woman}. This approach abstracts away grammatical difference between the sentences and concentrates on semantics and fits the proposed model as the respect for the head, which is a lexical entity, has to be found.

Sentences are different from words because they are part of the discourse and it is easy to come up with a pair of sentences that are similar in a certain situation but do not share grammatical structure at all, for example \textit{Yes} and \textit{They are on the table} are similar sentences if they are answers to the question \textit{Where are the cookies?} Questions the sentences answer are valid respects for similarity measurements, as well as entailment, paraphrase \cite{White:2015:WSE:2838931.2838932} or spatial categories \cite{ritter-EtAl:2015:*SEM2015}.

% TODO: Sentence similarity.
%
%       How can we measure sentence similarity?
%
%         1) Head in context. E.g. "The boy runs." vs. "The girl walks."
%         2) Full sentence simialrity. For example. "No" and "John took
%            the cookies" are similar with the respect to the question
%            "Do we have cookies?"
%         3) Transformational approach of either Kolmogorov complexity theory or "the number of changes between the referents".
%         4) Truth conditional equivalence and possible words.


\section{Conclustion}

Similarity evaluation needs to focus on how well a model is able to recover human similarity intuitions expressed as groupings, possibly around their focal points. We propose to treat it as a soft multi-class clustering problem \cite{White:2015:WSE:2838931.2838932}, where two entities belong to a same class if there is a similarity judgement for them (e.g.~\textit{apple} and \textit{banana} are similar because they are \textit{fruits}) and the strength is proportional to the number of such judgements, so we could express that \textit{apple} is more a \textit{fruit} than a \textit{company}.


\bibliographystyle{acl2016}
\bibliography{references,dmilajevs_publications}
\balance

\end{document}

