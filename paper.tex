\documentclass[11pt]{article}
\usepackage{acl2016}
\usepackage{times}

\usepackage{url}
\usepackage{latexsym}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{graphicx}
\usepackage{paralist}
\usepackage{mathtools}
\usepackage{dingbat}
\usepackage{subcaption}
\usepackage{balance}
\usepackage{gensymb}
\usepackage{marginnote}
\usepackage{adjustbox}

\makeatletter
\newcommand{\@BIBLABEL}{\@emptybiblabel}
\newcommand{\@emptybiblabel}[1]{}
\makeatother
\usepackage{hyperref}

\sloppy

% \aclfinalcopy % Uncomment this line for the final submission
% \def\aclpaperid{34} %  Enter the acl Paper ID here


\usepackage{color}
\newcommand{\todo}[1]{}
\renewcommand{\todo}[1]{{\color{red} TODO: {#1}}}

% \renewcommand{\baselinestretch}{0.95}

%\setlength\titlebox{5cm}

% You can expand the titlebox if you need extra space
% to show all the authors. Please do not make the titlebox
% smaller than 5cm (the original size); we will check this
% in the camera-ready version and ask you to change it back.

\title{On Similarity}

% \author{First Author \\
%   Affiliation / Address line 1 \\
%   Affiliation / Address line 2 \\
%   Affiliation / Address line 3 \\
%   {\tt email@domain} \\\And
%   Second Author \\
%   Affiliation / Address line 1 \\
%   Affiliation / Address line 2 \\
%   Affiliation / Address line 3 \\
%   {\tt email@domain} \\}

\date{}

\begin{document}

\maketitle

% \begin{abstract}
% % \input{abstract.tex}
% \end{abstract}

% \section{Introduction}
% \label{sec:introduction}

Similarity plays a crucial role in psychological theories of knowledge and behavior, for example, it is used to classify objects \cite{Tversky1977}.
%
Linguistic treatment of semantic similarity is based on two ideas: word occurrence patterns \emph{define} its meaning \cite{firth1957lingtheory}, while the difference in occurrence \textup{quantifies} the difference in meaning \cite{harris1954distributional}.

Practically, this leads to systems that use similarity to perform natural language processing tasks such as word sense disambiguation \cite{Schutze:1998:AWS:972719.972724}, information retrieval \cite{Salton:1975:VSM:361219.361220} and machine translation \cite{Dagan:1993:CWS:981574.981596}.

In recent years, similarity received a lot of attention as an intrinsic evaluation of meaning representations \cite{mikolov2013efficient,Bruni:2012:DST:2390524.2390544}, because in a complete text processing system it is difficult to measure performance of a single (similarity) component. As a result, a new generation of similarity datasets appeared from the computational linguistics community. The two notable datasets are MEN \cite{Bruni:2012:DST:2390524.2390544} and SimLex-999 \cite{hill2014simlex}. They surpasses older datasets stemmed in psychology (refer to \newcite{1986-13502-00119860101} for a comprehensive list of datasets) and information retrieval (for example \newcite{2002:PSC:503104.503110}) in quantity and attention to the evaluated relation. Both of them consist of word pairs assigned similarity (relatedness) scores based on human judgements.

Despite improvement, these datasets deviate from the psychological understanding of similarity. Intuitively, similarity is the amount of common properties between entities, and is implemented as a contrast model where ``the similarity between objects is expressed as a function of their common and distinctive features'' \cite{Tversky1977}.

One of the uncaptured properties of human similarity judgements is that categories are formed around \emph{focal points} \cite{1986-13502-00119860101}. Consider fruit names assessed for similarity. They will be arranged around the word \textit{fruit} in such a way that it is their nearest neighbor, making \textit{fruit} the focal point of the category. It is extremely important for a good semantic model to capture this property. Unfortunately, word pair similarity judgements do not capture this, as it is possible to arrange all fruit names close to \textit{fruit} but \textit{fruit} would not be the most common nearest neighbor. Moreover, as \newcite{turney2012domain} points out, categories that emerge from similarity judgements are different from lexical ontologies such as WordNet \cite{Miller:1995:WLD:219717.219748}, for example, \textit{traffic} and \textit{water} might be considered to be similar because of functional similarity exploited in hydrodynamic models of traffic, but their lowest common ancestor in WordNet is \textit{entity}.

Moreover, the similarity scores presented by the datasets are ambiguous as it is not really clear what low similarity values mean: incompatible notions (\textit{trick} and \textit{size}) or contrast in meaning (\textit{smart} and \textit{dumb}). For example, SimLex-999 assigns low similarity scores to the pairs, 0.48 and 0.55 out of 10 respectively, but \textit{smart} and \textit{dumb} have relatively much more in common than \textit{trick} and \textit{size}!

While the presence of incompatible pairings can be motivated as an attempt to control for false positives, they sound unnatural to human. Also, a large amount of random pairings\footnotemark{} might influence a particular arrangement of the clusters of similar words, for example, the cluster of fruit names has to be between the cluster of \textit{furious adjectives} and \textit{mass nouns}, even if such arrangement was not intended by the dataset creators.
\footnotetext{15\% of MEN entries have score less or equal to 10 out of 50 and by design 1000 word pairs are sampled from pairs that are assigned low cosine similarity scores by a text-based distributional model.}

Evaluation methods need to focus on how well a model is able to recover human similarity intuitions expressed as clusters (e.g~\textit{fruits}, \textit{company} and \textit{mass noun}). It can be seen as a soft multi-class clustering problem \cite{White:2015:WSE:2838931.2838932}, where two entities belong to a same class if there is a similarity judgement for them (e.g.~\textit{apple} and \textit{banana} are similar because they are \textit{fruits}) and the strength is proportional to the number of such judgements.

This leads two points this paper addresses. The similarity judgements should be collected in a different way which reflects human intuition about similarity. Even though vector space models of meaning measure similarity between words, it should not be (and can not) be contrasted directly with human judgements, instead the model needs to recover the concept clusters that humans define.

% remove publisher, month etc from conf proceedings:
% \bibliographystyle{acl-short}
\bibliographystyle{acl2016}
\bibliography{references,dmilajevs_publications}
\balance

\end{document}

