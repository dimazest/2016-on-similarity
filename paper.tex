\documentclass[11pt]{article}
\usepackage{acl2016}
\usepackage{times}

\usepackage{url}
\usepackage{latexsym}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{graphicx}
\usepackage{paralist}
\usepackage{mathtools}
\usepackage{dingbat}
\usepackage{subcaption}
\usepackage{balance}
\usepackage{gensymb}
\usepackage{marginnote}
\usepackage{adjustbox}

\sloppy

% \aclfinalcopy % Uncomment this line for the final submission
% \def\aclpaperid{34} %  Enter the acl Paper ID here


\usepackage{color}
\newcommand{\todo}[1]{}
\renewcommand{\todo}[1]{{\color{red} TODO: {#1}}}

% \renewcommand{\baselinestretch}{0.95}

%\setlength\titlebox{5cm}

% You can expand the titlebox if you need extra space
% to show all the authors. Please do not make the titlebox
% smaller than 5cm (the original size); we will check this
% in the camera-ready version and ask you to change it back.

\title{Treating Similarity with Respect: How to Evaluate Models of Meaning?}

% \author{First Author \\
%   Affiliation / Address line 1 \\
%   Affiliation / Address line 2 \\
%   Affiliation / Address line 3 \\
%   {\tt email@domain} \\\And
%   Second Author \\
%   Affiliation / Address line 1 \\
%   Affiliation / Address line 2 \\
%   Affiliation / Address line 3 \\
%   {\tt email@domain} \\}

\date{}

\begin{document}

\maketitle

\begin{abstract}

\end{abstract}

\section{Introduction}
\label{sec:introduction}

Similarity is the degree of resemblance between two objects or events \cite{WCS:WCS1282} and plays a crucial role in psychological theories of knowledge and behaviour, where it is used to explain such phenomena as classification and conceptualisation. \textit{Fruit} is a \emph{category} because it is a practical generalisation. Fruits are sweet and constitute deserts, so when one is presented with an unseen fruit, one can hypothesise that it is served toward the end of a dinner.

Generalisations are extremely powerful in describing a language as well. The verb \textit{runs} requires its subject to be singular. \textit{Verb}, \textit{subject} and \textit{singular} are categories that are used to describe English grammar. When one encounters an unknown word and is told that it is a verb, one will immediately have an idea about how to use it assuming that it is used similarly to other English verbs.

The semantic formalisation of similarity is based on two ideas. The occurrence patterns of a word \emph{define} its meaning \cite{firth1957lingtheory}, while the difference in occurrence between two words \emph{quantifies} the difference in their meaning \cite{harris1954distributional}. From a computational perspective, this motivates and guides development of similarity components that are embedded into natural language processing systems that deal with tasks such as word sense disambiguation \cite{Schutze:1998:AWS:972719.972724}, information retrieval \cite{Salton:1975:VSM:361219.361220} and machine translation \cite{Dagan:1993:CWS:981574.981596}.

Because it is difficult to measure performance of a single (similarity) component in a pipeline, datasets that focus on similarity are popular among computational linguists. Apart from a pragmatic attempt to alleviate the problems of evaluating similarity components, these datasets serve as an empirical test of the hypotheses of Firth and Harris, bringing together our understanding of human mind, language and technology.

Two datasets, namely MEN \cite{Bruni:2012:DST:2390524.2390544} and SimLex-999 \cite{hill2014simlex}, are currently widely used. They are designed especially for meaning representation evaluation and surpass datasets stemming from psychology \cite{1986-13502-00119860101} and information retrieval \cite{2002:PSC:503104.503110} in quantity by having more entries and, in case of SimLex-999, attention to the evaluated relation by distinguishing similarity from relatedness. The datasets provide similarity (relatedness) scores between word pairs.

In contrast to linguistic datasets which contain randomly paired words from a broad selection, datasets that come from psychology contain entries that belong to a single category such as \textit{verbs of judging} \cite{FILLENBAUM197454} or \textit{animal terms} \cite{HENLEY1969176}. The reason for category oriented similarity studies is that ``stimuli can only be compared in so far as they have already been categorised as identical, alike, or equivalent at some higher level of abstraction'' \cite{turner1987rediscovering}. Moreover, because of the \emph{extension effect} \cite{medin1993respects}, the similarity of two entries in a context is less than the similarity between the same entries when the context is extended. ``For example, \textit{black} and \textit{white} received a similarity rating of 2.2 when presented by themselves; this rating increased to 4.0 when \textit{black} was simultaneously compared with \textit{white} and \textit{red} (\textit{red} only increased 4.2 to 4.9)'' \cite{medin1993respects}. In the first case \textit{black} and \textit{white} are more dissimilar because they are located on the extremes of the greyscale, but in the presence of \textit{red} they become more similar because they are both monochromes.

Both MEN and SimLex-999 provide pairs that do not share any similarity to control for false positives, and they do not control for the comparison scale. This makes similarity judgements ambiguous as it is not clear what low similarity values mean: incompatible notions or contrast in meaning. SimLex-999 assigns low similarity scores to the incompatible pairs (0.48, \textit{trick} \textit{size}) and to antonymy (0.55, \textit{smart} and \textit{dumb}), but \textit{smart} and \textit{dumb} have relatively much more in common than \textit{trick} and \textit{size}!

This paper investigates how a similarity dataset with multiple categories should be built and considers what sentence similarity mean in this context.

\section{Dataset construction and model evaluation strategies}

\paragraph{Human similarity judgements}

To build a similarity dataset that contains non-overlapping categories, one needs to avoid comparison of incompatible pairs. However, that itself requires a priori knowledge of item similarity or belongingness to a category, making the problem circular. To get out of the vicious circle, one might erroneously  refer to an already existing taxonomy such as WordNet \cite{Miller:1995:WLD:219717.219748}. But in case of similarity, as \newcite{turney2012domain} points out, categories that emerge from similarity judgements are different from taxonomies. For example, \textit{traffic} and \textit{water} might be considered to be similar because of a functional similarity exploited in hydrodynamic models of traffic, but their lowest common ancestor in WordNet is \textit{entity}.

Since there is no way deciding upfront whether there is a similarity relation between two words, the data collection procedure needs test for both: relation existence and its strength. Numerical values, as has been shown in the introduction, do not fit this role, because of ambiguity. One way of avoiding the issue is to avoid asking humans for similarity judgements, but instead to ask them to list commonalities and differences between the objects. As one might expect, similarity scores correlate with the number of listed commonalities \cite{markman1991commonalities,Markman1996,medin1993respects}. For incompatible pairs, the commonality list should be empty, but the differences will enumerate properties that belong to one entity, but not another \cite{markman1991commonalities,medin1993respects}.

\paragraph{The entries in the dataset}

So far we have proposed a similarity judgement collection method that is robust to incompatible pairings. It also naturally gives rise to categories, because the absence of a relation between two entries means the absence of a common category. It still needs to be decided what words to include to the dataset.

To get a list of words that constitute the dataset, one might think of categories such as \textit{sports}, \textit{fruits}, \textit{vegetatbles}, \textit{judging verbs}, \textit{countries}, \textit{colours} and so on. Note, that at this point its acceptable to think of categories, because later the arbitrary category assignments will be reevaluated by humans. Once the list of categories is ready, each of them is populated with category instances, e.g.~\textit{plum}, \textit{banana} ans \textit{lemon} are all \textit{fruits}.

When the data is prepared, humans are asked to provide commonalities and differences between all pairs of every group. This serves two purposes. First, all expected similarities are judged, producing a dataset that can be seen as a merged version of category specific datasets. At this point, a good similarity model should provide meaning representation that are easily split to clusters: \textit{fruit} members and \textit{sport} members have to be separable.

Intra-category comparisons should be also performed, but because it impractical to collect pairwise judgement between the number of words of magnitude of hundreds, a reasonable sample should be taken. The intra-category comparisons will lead to unexpected category pairings, such as \textit{food} that contains \textit{plants} and \textit{fruits}, so the sampling procedure might be directed by the discovery of compatible pairs: when a \textit{banana} and \textit{potato} are shred some commonalities, \textit{fruits} and \textit{vegetables} should be more likely to be assessed.

\paragraph{Structure beyond proximity}

Human judgements validate the initial category assignment of items and provide new ones. If a category contains a superordinate, similarity judgements arrange category members around it \cite{1986-13502-00119860101}. For example, similarity judgements given by humans arrange fruit names around the word \textit{fruit} in such a way that it is their nearest neighbour, making \textit{fruit} the \emph{focal point} of the category of \textit{fruits}.

As an additional evaluation method, the model should be able to retrieve focal points. Therefore, a precaution should be taken before human judgement collection. If possible, categories should contain a subordinate.

Similarity evaluation needs to focus on how well a model is able to recover human similarity intuitions expressed as groupings, possibly around their focal points. We propose to treat it as a soft multi-class clustering problem \cite{White:2015:WSE:2838931.2838932}, where two entities belong to a same class if there is a similarity judgement for them (e.g.~\textit{apple} and \textit{banana} are similar because they are \textit{fruits}) and the strength is proportional to the number of such judgements, so we could express that \textit{apple} is more a \textit{fruit} than a \textit{company}. Models also should arrange subordinates to focal points giving labels to the clusters.

\section{Phrase and sentence similarity}

In the previous section we focused on the properties of similarity, illustrating it with word-word examples. This section is dedicated to the nuances of similarity measurement between words, phrases and sentences. We assume that similarity requires the agreement of the grammatical roles of the words or phrases.

A noun phrase can be similar to a noun, as in \textit{female lion} and \textit{lioness}, as between noun phrases with modifiers (\textit{yellow car} and \textit{taxi}), so the same similarity principles can be applied to phrases as to words. In this case, similarity is measured in \emph{context}. It is still comparison of heads which meaning is modified by arguments they appear with \cite{Dinu:2010:MDS:1870658.1870771,mitchell2010composition}. With verbs this idea can be applied to compare transitive verbs with intransitive. For example, \textit{to cycle} is similar to \textit{ride a bicycle}.

Sentential similarity can be explained in several ways. First of all, it might be seen as the similarity of the heads in the contexts. That is, the similarity between \textit{sees} and \textit{notices} in \textit{John \textbf{sees} Mary} and \textit{John \textbf{notices} a woman}. This approach abstracts away grammatical difference between the sentences and concentrates on semantics and fits the proposed model as the respect for the head, which is a lexical entity, has to be found.

Sentences are different from words because they are part of the discourse and it is easy to come up with a pair of sentences that are similar in a certain situation but do not share grammatical structure at all, for example \textit{Yes} and \textit{They are on the table} are similar sentences if they are answers to the question \textit{Where are the cookies?} Questions the sentences answer are valid \textit{respects} for similarity measurements, as well as entailment, paraphrase \cite{White:2015:WSE:2838931.2838932} or spatial categories \cite{ritter-EtAl:2015:*SEM2015}.

% TODO: Sentence similarity.
%
%       How can we measure sentence similarity?
%
%         1) Head in context. E.g. "The boy runs." vs. "The girl walks."
%         2) Full sentence simialrity. For example. "No" and "John took
%            the cookies" are similar with the respect to the question
%            "Do we have cookies?"
%         3) Transformational approach of either Kolmogorov complexity theory or "the number of changes between the referents".
%         4) Truth conditional equivalence and possible words.


\section{Conclusion}


\bibliographystyle{acl2016}
\bibliography{references,dmilajevs_publications}
\balance

\end{document}

